{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572a0d7a",
   "metadata": {},
   "source": [
    "<table class=\"notebook-buttons\" align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/JeremieGince/DefiProgFest2023/blob/main/Gym-Tutorial.ipynb\"><img src=\"https://github.com/NeuroTorch/NeuroTorch/blob/main/images/colab_logo_32px.png?raw=true\" width=32px height=32px  />Run in Google Colab</a>\n",
    "</td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/JeremieGince/DefiProgFest2023/blob/main/Gym-Tutorial.ipynb\"><img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=32px height=32px />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/JeremieGince/DefiProgFest2023/blob/main/Gym-Tutorial.ipynb\"><img src=\"https://github.com/NeuroTorch/NeuroTorch/blob/main/images/download_logo_32px.png?raw=true\" width=32px height=32px />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a41daa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98d9a2",
   "metadata": {},
   "source": [
    "# Gym - Lunar lander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c43eef",
   "metadata": {},
   "source": [
    "Liens vers la documentation: \n",
    "- [Gym-basic_usage](https://www.gymlibrary.dev/content/basic_usage/)\n",
    "- [Gym-core](https://www.gymlibrary.dev/api/core/)\n",
    "- [Lunar Lander](https://www.gymlibrary.dev/environments/box2d/lunar_lander/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59475774",
   "metadata": {},
   "source": [
    "Cet environnement `Gym` est un problème d'optimisation qui nécessite de faire atterrir (alunir?) un *lunar lander* entre deux drapeaux en lui envoyant des commandes en temps réel. Pour un environnement exécuté en mode discret (`continuous = False`), les commandes sont de forme binaire, utilisant toujours la pleine puissance du moteur. Les quatre commandes possibles sont:\n",
    "\n",
    "- Ne rien faire (`0`)\n",
    "- Activer le moteur droite (`1`)\n",
    "- Activer le moteur central (`2`)\n",
    "- Activer le moteur gauche (`3`)\n",
    "\n",
    "Afin de déterminer les commandes appropriées selon l'état de la situation, les différentes coordonnées spatiales du vaisseau sont rendues accessibles dans un vecteur d'observation (`observation`) qui contient, dans l'ordre, les huit coordonnées suivantes:\n",
    "\n",
    "- Position horizontale (intervalle `[-1.5, 1.5]`)\n",
    "- Position verticale (intervalle `[1.5, -1.5]`)\n",
    "- Vitesse horizontale (intervalle `[-5, 5]`)\n",
    "- Vitesse verticale (intervalle `[-5, 5]`)\n",
    "- Angle (intervalle  `[-3.14, 3.14]`)\n",
    "- Vitesse angulaire (intervalle `[-5, 5]`)\n",
    "- Contact pied gauche (`True` or `False`)\n",
    "- Contact pied droite (`True` or `False`)\n",
    "\n",
    "L'environnement est initialisé aléatoirement, puis exécuté dans une boucle. À chaque itération de la boucle, les coordonnées du vaisseau sont mises à jour, puis un ensemble de variables est retourné à l'utilisateur, qui doit utiliser celles-ci afin de déterminer la prochaine commande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c46ebc",
   "metadata": {},
   "source": [
    "Jetons un coup d'oeil à une procédure d'atterrissage où les commandes sont déterminées aléatoirement à chaque itération:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d4b0568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Github\\DefiProgFest2023\\venv\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "observation, info = env.reset(seed=None)\n",
    "terminal = False\n",
    "while not terminal:\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    terminal = done or truncated\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc04ccd7",
   "metadata": {},
   "source": [
    "Sans grande surprise, l'atterrissage est une véritable catastrophe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14abadc9",
   "metadata": {},
   "source": [
    "À chaque itération, une valeur de récompense (`reward`) est retournée à l'utilisateur. Des valeurs positives sont attribuées lorsque le vaisseau se dirige vers les drapeaux, ainsi que lorsque l'atterrissage est réussi. À l'inverse, des valeurs négative sont retournées à chaque fois que les moteurs sont utilisés, ainsi que lorsque le vaisseau collisionne avec le sol (pour plus de détails sur le système de pointages, voir la documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47aadb2",
   "metadata": {},
   "source": [
    "Nous pouvons ainsi cumuler les récompenses sur toute la durée de la simulation, afin d'obtenir un score de récompense totale qui permet de juger de la performance de la procédure d'atterrissage. Effectuons l'évaluation de notre pilote aléatoire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b182b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Rewards: -103.558\n",
      "The eagle has not landed.\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "\n",
    "observation, info = env.reset(seed=None)\n",
    "\n",
    "terminal = False\n",
    "cumulative_rewards = 0\n",
    "\n",
    "while not terminal:\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    cumulative_rewards += reward\n",
    "    terminal = done or truncated\n",
    "\n",
    "print(f'Cumulative Rewards: {cumulative_rewards:.3f}')\n",
    "if cumulative_rewards < 0:\n",
    "    print(f\"The eagle has not landed.\")\n",
    "if cumulative_rewards >= 200:\n",
    "    print(f\"The eagle has landed.\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ccaa9",
   "metadata": {},
   "source": [
    "De toute évidence, il serait possible de faire mieux. Il faut désormais exploiter le vecteur `observation` retourné à chaque itération, soit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b26834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3570746  -0.08372779 -0.74975836 -0.709012   -0.04089577  4.172947\n",
      "  1.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544021ba",
   "metadata": {},
   "source": [
    "Ce dernier devrait contenir toute l'information nécessaire afin d'établir une procédure qui permet de déterminer, à chaque itération, la bonne commande à effectuer.\n",
    "\n",
    "Vous devez maintenant concevoir un algorithme qui permet de faire atterrir le vaisseau **tout en cumulant le plus de points possible**. Compte tenu la nature aléatoire de la tâche, la performance moyenne sur 100 simulations sera évaluée. Pour accélérer l'exécution des simulations, le mode `render_mode=rgb_array`. Bien entendu, vous devriez utiliser le mode `human` pour visualiser les performances de votre algorithme pendant son développement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17b8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_rewards_list = []\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "for _ in range(100):\n",
    "    observation, info = env.reset(seed=None)\n",
    "    \n",
    "    terminal = False\n",
    "    cumulative_rewards = 0\n",
    "    \n",
    "    while not terminal:\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, truncated, info = env.step(action)\n",
    "        cumulative_rewards += reward\n",
    "        terminal = done or truncated\n",
    "\n",
    "    cumulative_rewards_list.append(cumulative_rewards)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04e5301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cumulative rewards: -171.932\n",
      "The eagle has, on average, not landed.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average cumulative rewards: {np.mean(cumulative_rewards_list):.3f}\")\n",
    "if np.mean(cumulative_rewards_list) < 0:\n",
    "    print(\"The eagle has, on average, not landed.\")\n",
    "if np.mean(cumulative_rewards_list) >= 200:\n",
    "    print(f\"The eagle has, on average, landed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2f391",
   "metadata": {},
   "source": [
    "La balle est maintenant dans votre camp. The eagle *must* land."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e60939b",
   "metadata": {},
   "source": [
    "# Comment tester son agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fbe9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.tester import LunarLanderPerformanceTest, LunarLanderTester, LunarLanderPEP8Test\n",
    "from main import get_env_configs\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb158acd",
   "metadata": {},
   "source": [
    "### L'agent aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4ade0c",
   "metadata": {},
   "source": [
    "Ici, on créé notre agent pour éventuellement le tester. Cette class vient du fichier [lunar_lander_agent.py](./lunar_lander_agent.py) où vous allez devoir implémenter le votre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a0d1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunarLanderAgent:\n",
    "\tdef __init__(self, env_config: dict, **kwargs):\n",
    "\t\tself.env_config = env_config\n",
    "\t\tself.set_default_env_config()\n",
    "\t\tself.observation_as_rgb = self.env_config.get(\"render_mode\", None) == \"rgb_array\"\n",
    "\t\n",
    "\tdef set_default_env_config(self):\n",
    "\t\tself.env_config.setdefault('render_mode', None)\n",
    "\t\tself.env_config.setdefault('id', \"LunarLander-v2\")\n",
    "\t\n",
    "\tdef make_env(self):\n",
    "\t\tenv = gym.make(**self.env_config)\n",
    "\t\treturn env\n",
    "\t\n",
    "\tdef get_action(self, observation: np.ndarray) -> Union[int, np.ndarray]:\n",
    "\t\tenv = self.make_env()\n",
    "\t\taction = env.action_space.sample()\n",
    "\t\tenv.close()\n",
    "\t\treturn action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821cd8f",
   "metadata": {},
   "source": [
    "### Les tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c861b0",
   "metadata": {},
   "source": [
    "Dans la prochaine cellule, on vous montre le code à utiliser pour tester son agent dans l'environnement de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c66a1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Echelon 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.49it/s, [Echelon 0: 0.00 %]]\n",
      "Running Echelon 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.39it/s, [Echelon 1: 0.00 %]]\n",
      "Running Echelon 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.65it/s, [Echelon 2: 0.00 %]]\n",
      "Running Echelon 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.09it/s, [Echelon 3: 0.00 %]]\n",
      "Running Echelon 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.12it/s, [Echelon 4: 0.00 %]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PEP8: 100.00 %]\n",
      "[Echelon 0: 0.00 %]\n",
      "[Echelon 1: 0.00 %]\n",
      "[Echelon 2: 0.00 %]\n",
      "[Echelon 3: 0.00 %]\n",
      "[Echelon 4: 0.00 %]\n",
      "Test results saved to './test_results.txt'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "configs_file_path = \"./env_configs.json\"\n",
    "\n",
    "# On instantie l'objet de test\n",
    "tester = LunarLanderTester()\n",
    "\n",
    "# On ajoute le test de PEP8\n",
    "# file_path doit être égal à votre fichier `lunar_lander_agent.py` où vous allez implémenter votre agent.\n",
    "pep8_test = LunarLanderPEP8Test(name=\"PEP8\", file_path=\"./lunar_lander_agent.py\")\n",
    "tester.add_test(pep8_test)\n",
    "\n",
    "# On ajoute les tests de performances en utilisant les configurations de test.\n",
    "env_configs = get_env_configs(configs_file_path=configs_file_path)\n",
    "for config_name, env_config in env_configs.items():\n",
    "    performance_test = LunarLanderPerformanceTest(\n",
    "        name=config_name,\n",
    "        agent=LunarLanderAgent(env_config=env_config),\n",
    "        env_config=env_config,\n",
    "    )\n",
    "    tester.add_test(performance_test)\n",
    "\n",
    "# On lance les tests\n",
    "tester.run()\n",
    "\n",
    "# On affiche les tests\n",
    "print(tester)\n",
    "\n",
    "# On sauvegarde les résultats \n",
    "tester.to_file(file_path=\"./test_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893b943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
